{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 1.2 - Explore Data\n",
    "\n",
    "In this lesson, you will learn how to do exploratory data analysis (EDA). In the EDA phase, you need to understand what information is in your dataset in order to later clean and prepare the data for predictive analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python libraries\n",
    "\n",
    "Libraries have pre-defined code for other functions that are not included in basic Python. Once a library has been imported, any of its functions can be used throughout the entire notebook. Some libraries have long names that may be easy to misspell when using its functions, so it is common practice to assign a library to an alias name using `as`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # numpy used for linear algebra functions\n",
    "import pandas as pd # pandas used to explore and manipulate dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "This notebook is a file in which we will explore the data but before that can be done, we must first read in a copy of it from the file that it's stored in. The `pandas` library will read the information in a file and then format it into a row-column structure called a ***dataframe***. Dataframes are similar to a table or spreadsheet and can be used within Python to explore and manipulate items in the rows or columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV files\n",
    "\n",
    "CSV stands for \"comma separated values\". It is a plain text file where each value in a line is separated by some delimiter (usually commas but can be tabs, semicolons, spaces, etc.). In `pandas` the function to read data from a CSV file is `.read_csv(name of file)`. The path to the file with data should be typed inside the parentheses (as a string) of the `.read_csv()` function. If the data file and the notebook file are located in the same folder, then just the name of the file is required. The `.read_csv()` function assumes that the first line of information in the file will be the column header names for the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load a csv file named \"smallgradesh.csv\" located in the datasets folder\n",
    "\n",
    "location = \"datasets/smallgradesh.csv\"\n",
    "df = pd.read_csv(location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframes\n",
    "\n",
    "Unlike spreadsheets in tools such as Microsoft Excel, dataframes are not meant to be viewed in full detail (meaning, scroll through every single row of information). Instead, to verify that the data was loaded in properly, the `.head()` and `.tail()` functions show several rows and columns within the dataset. By default, the `.head()` and `.tail()` functions show the first/last five rows of the dataset. The number of rows shown can be altered by setting the number inside the function parentheses. However, if the number of rows requested is excessive, then the dataframe will only show several rows from the top of the dataframe, skip the middle section, and then show the last few rows. Additional features of the data can be verified using other exploratory functions to determine if any data formatting needs to be done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# this will show first 5 rows in the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*NOTE*: In Jupyter notebook, whenever you do not remember what a function does or need to know what parameters/arguments can be used in it, just type the function name witha question mark at the end (no parentheses) and run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.head?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will show the last 3 rows of the dataframe\n",
    "df.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data without headers\n",
    "\n",
    "If the file (CSV, Excel, etc.) does not contain column header names, then the argument `header=None` is used to read the first line in the file as the first row in the dataframe. In addition, you can add column header names while reading in the data using the `names=[list of column names]` argument in the function. Column headers can also be added after the data has been loaded as a dataframe - first, type the dataframe variable name and use the `.columns` function (this will access the names of the columns). Then on the right side of an equal sign (assignment operator) type a Python list of all of the new header names in the position order of the columns (this also works for renaming columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location2 = \"datasets/smallgrades.csv\"\n",
    "\n",
    "# CSV file that does not have column header names\n",
    "# Python creates index position placeholder names for the columns\n",
    "\n",
    "df_nohead = pd.read_csv(location2, header=None) #try w/o header=None\n",
    "\n",
    "df_nohead.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the same file in the previous cell\n",
    "# this time we will add on column header names as the data is loaded\n",
    "\n",
    "df_during = pd.read_csv(location2, names=['Name', 'Grade'])\n",
    "\n",
    "df_during.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verify that this dataframe has no column header names\n",
    "df_nohead.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# add header names to \"df_nohead\" dataframe\n",
    "\n",
    "df_nohead.columns = ['Name', 'Grade']\n",
    "df_nohead.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excel files\n",
    "\n",
    "In `pandas` the function to read in data from an Excel file is `.read_excel()` and works similarly to the `.read_csv()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data from Excel file\n",
    "\n",
    "location = \"datasets/gradedata.xlsx\"\n",
    "df = pd.read_excel(location) #overwrites the info from the df variable in the examples above\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a file from dataframe\n",
    "\n",
    "Usually after the data has been manipulated and transformed into a format that the user is satisfied with, it may be the case that the information is going to be used within another program (Excel, Tableau, etc.). Because the data cannot be directly sent from Jupyter notebook to another application, we can create a file from the dataframe. CSV is the easiest format to use for the data but other file formats can be used as well (Excel, JSON). \n",
    "\n",
    "#### Zip function\n",
    "- Is a Python built-in function that allows us to combine corresponding elements from multiple sequences into a single list of tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create fake data\n",
    "\n",
    "names = ['Bob','Jessica','Mary','John','Mel']\n",
    "grades = [76,95,77,78,99]\n",
    "GradeList = list(zip(names,grades))\n",
    "\n",
    "df = pd.DataFrame(data = GradeList, columns=['Names','Grades'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export data to CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export data to a file called \"studentgrades.csv\"\n",
    "# file will be created in the same folder as the notebook, unless specified\n",
    "\n",
    "df.to_csv('studentgrades.csv',index=False,header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export data to Excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Excel file from dataframe\n",
    "# \"engine\" parameter tells file what Excel format encoding (.xls, .xlsx) to create\n",
    "\n",
    "writer = pd.ExcelWriter('dataframe.xlsx', engine='xlsxwriter')\n",
    "df.to_excel(writer, sheet_name='Sheet1')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export different dataframes to separate sheets in same Excel file\n",
    "\n",
    "writer = pd.ExcelWriter('dataframe.xlsx', engine='xlsxwriter')\n",
    "\n",
    "df.to_excel(writer, sheet_name='Sheet1')\n",
    "df_nohead.to_excel(writer, sheet_name='Sheet2')\n",
    "\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Features\n",
    "\n",
    "The first steps in the EDA process should be to verify that the data is properly loaded (using `.head()` or `.tail()`), checking the number of rows and columns, finding out what columns exist in the dataset, and also the data type of each column.\n",
    "\n",
    "### Exploratory Analysis\n",
    "It is use for gaining a better understanding of data aspects like:\n",
    "- main features of data\n",
    "- variables and relationships that hold between them\n",
    "- identifying which variables are important for our problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load gradedata.csv file\n",
    "\n",
    "location = \"datasets/gradedata.csv\"\n",
    "df = pd.read_csv(location)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total number of rows in dataframe\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the number of rows and columns in a dataframe\n",
    "# format is (# rows, # columns)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show the column names in the dataset\n",
    "#or print(df.columns)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show the data type of each column\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of non-null (missing) values in each column\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive Statistics\n",
    "\n",
    "Descriptive statistics, also called summary statistics, are a way to get information about the characteristics of a column. Common features include the maximum and minimum values, the total (sum) of all the values, and the mean or median (measures of central tendency).\n",
    "\n",
    "To access a column in the dataframe use the dataframe variable name followed by a pair of square brackets with the name of the column (as a string) inside of it (similar to getting the value from a dictionary using a key)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_name['column name'] to access a column\n",
    "\n",
    "# maximum age (oldest student)\n",
    "df['age'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimum age (youngest student)\n",
    "df['age'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# total sum of ages\n",
    "df['age'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean\n",
    "Refers to the mean or average that is used to derive the central tendency of the data in question. It is determined by adding all the data points in a population and then dividing the total by the number of points. The resulting number is known as the mean or the average.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean age (arithmetic average)\n",
    "df['age'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Median\n",
    " - The \"middle\" of a sorted list of numbers. \n",
    " - If the number of terms is odd, then the median is the value of the term in the middle.\n",
    " - If the number of terms is even, then the median is the average of the two terms in the middle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# middle average age (median)\n",
    "df['age'].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mode\n",
    "- Is the value of the term that occurs the most often.\n",
    "- Sometimes there is more than one mode. This happens when two or more terms occur with equal frequency, and more often than any of the others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mode age (most frequently occuring) of all students\n",
    "# can have two or more most frequent values\n",
    "df['age'].mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard deviation\n",
    "- Is a measure of the amount of variation or dispersion of a set of values.[1] A low standard deviation indicates that the values tend to be close to the mean (also called the expected value) of the set, while a high standard deviation indicates that the values are spread out over a wider range.\n",
    "- In statistics, the 68–95–99.7 rule, also known as the empirical rule, is a shorthand used to remember the percentage of values that lie within a band around the mean in a normal distribution \n",
    "\n",
    "Calculate Standard Deviation\n",
    "\n",
    "\n",
    "- The mean value is calculated by adding all the data points and dividing by the number of data points.\n",
    "- The variance for each data point is calculated, first by subtracting the value of the data point from the mean. Each of those resulting values is then squared and the results summed. The result is then divided by the number of data points less one.\n",
    "- The square root of the variance—result from no. 2—is then taken to find the standard deviation.\n",
    "\n",
    "\n",
    "<img src=\"standardDeviation.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard deviation (distance away from mean)\n",
    "df['age'].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Describe function\n",
    "df.describe()\n",
    "\n",
    "- NaN values has been ignored while calculating these statistical values.\n",
    "- It excludes character column and calculate summary statistics only for numeric columns\n",
    "- Function gives the mean, std and IQR values. \n",
    "- The interquartile range (IQR) is the difference between the 75th and 25th percentile of the data. It is a measure of the dispersion similar to standard deviation or variance, but is much more robust against outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#descriptive statistics\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unique ages (distinct values)\n",
    "df['age'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many students are in each age group\n",
    "# first value is the mode\n",
    "df['age'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary statistics by group categories\n",
    "\n",
    "While descriptive statistics can show a general overview about a dataset, calculating statistics for different categories within a feature (column) can identify patterns and trends specific to that group. The `.groupby()` and `.pivot_table()` functions both communicate statistical information within a particular demographic.\n",
    "\n",
    "#### groupby() function \n",
    "- Is used to split the data into groups based on some criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doesn't do anything on its own\n",
    "# groupby function must be combined with a statistical calculation\n",
    "df.groupby('gender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates table of averages per gender category for all numerical-type columns \n",
    "df.groupby(df['gender']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average hours per gender group\n",
    "df.groupby(df['gender'])['hours'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average hours and exercise per gender group\n",
    "df.groupby(df['gender'])['hours', 'exercise'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first group by gender then group by age category\n",
    "# average hours of study by gender and age\n",
    "df.groupby(['gender', 'age'])['hours'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pivot table\n",
    "- This tool enabled users to automatically sort, count, total, or average the data stored in one table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #pivot table default statistical function is mean\n",
    "pd.pivot_table(df, index=['gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change statistical function to median\n",
    "pd.pivot_table(df, index=['gender'], aggfunc='median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate mean for only the \"age\" column\n",
    "pd.pivot_table(df, values=['age'], index=['gender'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing data\n",
    "\n",
    "Data is messy, and one of the most common forms is missing information. In the data cleaning phase, we will learn how to handle rows and columns with missing values but first we need to identify where there is missing information. Missing values in Python are typically called ***null values*** and in a dataframe, missing cells have `NaN` (for \"not a number\") as a visual placeholder. To find the total number of missing values in a column, the `.isnull()` will create a column of True/False values (also called \"boolean\" values) depending on if the value in that cell is missing (null = True, not null = False). Then use the `.sum()` function on the resulting True/False to get a count of the number of `True` values for the missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load data from file and show first 5 rows of dataframe\n",
    "\n",
    "filename = \"datasets/gradedatamissing.csv\"\n",
    "df_missing = pd.read_csv(filename)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total number of non-missing values in each column\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total missing values per column\n",
    "df_missing.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duplication\n",
    "\n",
    "When looking for duplicates in `pandas`, the `.duplicated()` function by default searches for duplication across an entire row (meaning, all the values in one row are exactly the same as all the values in another row). It produces a column of boolean values (`True`/`False`) indicated if the row is a duplicate. The first time the `.duplicated()` function sees a row of information, it is not considered as duplicate (because it has not seen any other similar rows of data). However, whenever the function comes across the same information again, then that row (and any following rows that contain the same data) are then marked as duplicates. To look for duplicates only for specific columns, then use the argument `.duplicated(subset=[list of column names])`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create fake data with duplicates\n",
    "\n",
    "names = ['Jessica','John','Bob','Jessica','Mary','John','Mel','Mel']\n",
    "grades = [95,78,76,95,77,78,99,100]\n",
    "dupe_data = list(zip(names,grades))\n",
    "\n",
    "df = pd.DataFrame(data = dupe_data, columns=['Names', 'Grades'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the duplicate rows (same information in both columns for 2+ rows)\n",
    "dupe = df.duplicated()\n",
    "dupe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the rows where there are True values\n",
    "# duplicate of Jessica - 95; John - 78\n",
    "df.loc[dupe]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for duplicates only in the \"Names\" column (will ignore \"Grades\")\n",
    "# Jessica, John, and Mel are name duplicates\n",
    "\n",
    "dupe_name = df.duplicated(subset=['Names'])\n",
    "df.loc[dupe_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subset a dataframe\n",
    "\n",
    "Dataframe rows and columns can be referred to in two different ways - either by their label or by their index position. Column labels are the header names and are typically purposely named in the dataset. User-defined row labels are less common; if there are not any specific labels given to the rows, then the index position also becomes the label (same goes for column labels). Because Python positions start from zero, the first column or row is always index position zero, no matter what labels are assigned to the row.\n",
    "\n",
    "When selecting rows or column from a dataframe, it returns a smaller dataframe called a subset, which can then be assigned to its own variable name. If the original dataframe had default labels (using position) assigned to the rows (and columns, if applicable) then the subset labels will be inherited from the original dataframe, even though the index positions are different. For example, if a row had a label `4` and was also in index position `4`, then was assigned to a subset where it is now the first row, then the label would still be `4` but the position is `0`. \n",
    "\n",
    "There are two functions that are used to select rows or columns in a dataframe:\n",
    "\n",
    "- `dataframe_name.loc[row label]`: select rows by label name\n",
    "- `dataframe_name.iloc[row position]`: select rows by index position number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    A    B\n",
       "0  10   no\n",
       "1  20  yes\n",
       "2  40  yes\n",
       "3  50   no"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dataframe \"A\"\n",
    "# dataframe \"A\" has default index positions as labels\n",
    "\n",
    "colA = [10, 20, 40, 50]\n",
    "colB = ['no', 'yes', 'yes', 'no']\n",
    "\n",
    "A_B = list(zip(colA, colB))\n",
    "\n",
    "df_A = pd.DataFrame(data=A_B, columns=['A', 'B'])\n",
    "df_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A    10\n",
       "B    no\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select the row from dataframe \"A\" with label name 0\n",
    "df_A.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A    10\n",
       "B    no\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select the row from dataframe \"A\" with index position 0\n",
    "df_A.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>10</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>20</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>40</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>50</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    A    B\n",
       "a  10   no\n",
       "b  20  yes\n",
       "c  40  yes\n",
       "d  50   no"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dataframe \"B\"\n",
    "# dataframe \"B\" has user-defined labels\n",
    "index = ['a', 'b', 'c', 'd']\n",
    "colA = [10, 20, 40, 50]\n",
    "colB = ['no', 'yes', 'yes', 'no']\n",
    "\n",
    "df_B = pd.DataFrame(data=A_B, columns=['A', 'B'], index=index)\n",
    "\n",
    "df_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A     20\n",
       "B    yes\n",
       "Name: b, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select the row in dataframe \"B\" with the row label name \"b\"\n",
    "df_B.loc['b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A     20\n",
       "B    yes\n",
       "Name: b, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select the row in dataframe \"B\" with index position 1\n",
    "# same row as previous cell; different way of selecting it\n",
    "df_B.iloc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's see how this can get tricky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    A    B\n",
       "0  10   no\n",
       "1  20  yes\n",
       "2  40  yes\n",
       "3  50   no"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataframe \"C\" is a copy of dataframe \"A\"\n",
    "df_C = df_A.copy()\n",
    "df_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    A    B\n",
       "2  10   no\n",
       "1  20  yes\n",
       "0  40  yes\n",
       "3  50   no"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataframe \"D\" has index label names that are numbers (but not the default index positions)\n",
    "index = [2,1,0,3]\n",
    "colA = [10, 20, 40, 50]\n",
    "colB = ['no', 'yes', 'yes', 'no']\n",
    "\n",
    "df_D = pd.DataFrame(data=A_B, columns=['A', 'B'], index=index)\n",
    "df_D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rows can also be selected as a group (not just a single row) by including the starting row and ending row with a colon between them inside the square brackets (`dataframe_name[start:end]`). When using the `.iloc` function to choose rows, it works similarly to Python list slicing - it chooses the starting index row but the ending index row position is not inclusive. However, for choosing a group of rows by the label name (`.loc`), the ending row label value is included in the subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    A    B\n",
       "2  10   no\n",
       "1  20  yes\n",
       "0  40  yes"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# choose index position 0 through the index position before 3\n",
    "df_D.iloc[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    A    B\n",
       "0  40  yes\n",
       "3  50   no"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select label '0' and all the rows that are in between and ending with the row with label '3'\n",
    "df_D.loc[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    A    B\n",
       "0  10   no\n",
       "1  20  yes\n",
       "2  40  yes"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select rows starting from index position 0 through BUT NOT INCLUDING position 3\n",
    "df_C.iloc[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    A    B\n",
       "0  10   no\n",
       "1  20  yes\n",
       "2  40  yes\n",
       "3  50   no"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select with index label '0' and everything in between and include the label '3'\n",
    "df_C.loc[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing columns\n",
    "\n",
    "Just as selecting rows reduces the size of the dataframe into a subset where we can study the particular characteristics of that group, we may also want to keep certain columns from the dataset to make it easier to focus on the relevant information for analysis. To choose columns to keep for the subset dataframe, use the syntax `dataframe_name[[list of columns]]` (a list of column names inside another pair of square brackets to select that list as a dataframe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the gradedata.csv file\n",
    "\n",
    "location = \"datasets/gradedata.csv\"\n",
    "df = pd.read_csv(location)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the columns from the list of names \"fname\", \"lname\", \"hours\", and \"grade\"\n",
    "small_df = df[['fname', 'lname', 'hours', 'grade']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show first 5 rows of smaller dataframe with those columns only\n",
    "small_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus Code!\n",
    "\n",
    "Although not a requirement for the material that will be covered in this course, below is a code example of a task challenge you may encounter while working on a project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load multiple data files\n",
    "\n",
    "If you are faced with multiple files with information you want to aggregate into a single dataframe, instead of loading each file individually as their own separate dataframes, the `glob` library will gather a list of file names from a directory and then you can use `pandas` to create the entire dataframe automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob #used to read file names in directory\n",
    "\n",
    "# make an empty dataframe called \"all_data\"\n",
    "# this will be used to add each file's data to previous data added\n",
    "all_data = pd.DataFrame()\n",
    "\n",
    "# iterate through each Excel file in the datasets directory with a name starting with \"data\"\n",
    "for file in glob.glob(\"datasets/data*.xlsx\"):\n",
    "    \n",
    "    #make a dataframe with that file's data\n",
    "    df = pd.read_excel(file)\n",
    "    \n",
    "    # append (attach) the small dataframe to the overall dataframe (\"all_data\")\n",
    "    all_data = all_data.append(df, ignore_index=True)\n",
    "\n",
    "# view the number of rows in dataframe\n",
    "# each data file had 100 rows of information (3 total files)\n",
    "len(all_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
